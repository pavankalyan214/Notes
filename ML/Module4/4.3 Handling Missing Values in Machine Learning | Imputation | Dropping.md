There are mainly two methods to handle missing values so those methods are nothing but imputation and dropping 

![image](https://github.com/user-attachments/assets/8ecaf1dd-d177-445f-bf5a-ae5f6ae96280)


1.Imputing:

 i hope you know that in machine learning or data science we use data sets so and this data set is used to train our machine learning model and once our machine learning model
is trained with this data set it can make new predictions and that data set may contain a lot of missing values and we cannot feed this data set with missing values to our machine learning model so we need to replace all those machine learning you know all those missing values 

```bash
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
```


# loading the dataset to a Pandas DataFrame
```bash
dataset = pd.read_csv('/content/Placement_Dataset.csv')


dataset.head() # to see first 5 rows of the data set 


dataset.shape # number of rows and columns


dataset.isnull().sum()  # to see count of missing values in each column 
```
![image](https://github.com/user-attachments/assets/1eb9e160-2508-439c-8361-b28e783a4e65)

 there are two methods one is imputation and the second method is dropping, dropping is nothing but just dropping or deleting all the rows which has missing values, but this is not a efficient way to do this, when you have a very large dataset say you have uh you know 20 000 data points 30 000 data points or you know lacks of data points in those cases you can just drop the missing values so it won't be a very big factor but when you have a very small data set like 200 300 or within thousand dropping the missing values is not an ideal method 


So its better to use Imputation

imputation is nothing but using some proper statistical values and replacing these uh missing values with those statistical values so those statistical measures are nothing but **mean** **median** and **mode**

these three terms mean median mode are also called as **central tendencies**


![image](https://github.com/user-attachments/assets/ce6d3db7-f055-4745-93f7-0cc0c690effd)

Mean: 
1.Arrance the values in ascending order 


Mean : Average of all the values 
[1,2,3,4,5]

Median:
2.Number of values
In case of add number values like [1,2,3,4,5] --> here median is middle values which is 3
In case of even numbers [1,2,3,4,5,6] --> here we will find the mean or average  of 3,4  in this case median is 3.5

Mode :
is the number which has most frequent 
[1,2,3,3,4,5,6]  --> 3


When we need use these 


# analyse the distribution of data in the salary, salary colum as it has missing values
fig, ax = plt.subplots(figsize=(8,8))
sns.distplot(dataset.salary)
![image](https://github.com/user-attachments/assets/66dd3aa5-0ce1-405f-9b91-e1f3bd5e28fa)


Above curve is called skew

For the above graph we can observer that the data is high distributed in between 0.2 and to 0.3 we can see it is more in 0.25
But here we can see there are values at 0.7 0.4 and 0.9 in this case these values are outlayers and these values increase the mean
this kind of skew distribution in those cases we will use either median or mode as our you know replacement for the missing values okay but when you have one you know almost normally distributed values where you have uh values distributed in all the magnitude in such cases we can take mean as our replacement for our missing value so in this case as the distribution is more on one side as we get a skew curve we are going to replace the missing values with median or mode



Replace the missing values with Median value
```bash
dataset['salary'].fillna(dataset['salary'].median(),inplace=True)

dataset.isnull().sum()

# filling missing values with Mean value:
 dataset['salary'].fillna(dataset['salary'].mean(),inplace=True)

# filling missing values with mode value:
 dataset['salary'].fillna(dataset['salary'].mode(),inplace=True)
```
2.Dropping Method

```bash
salary_dataset = pd.read_csv('/content/Placement_Dataset.csv')

salary_dataset.shape

salary_dataset.isnull().sum()
```

# drop the missing values
```bash
salary_dataset = salary_dataset.dropna(how='any') # dropna will remove all missing values and any means it will remove all the missing values 

salary_dataset.isnull().sum()

salary_dataset.shape
```
