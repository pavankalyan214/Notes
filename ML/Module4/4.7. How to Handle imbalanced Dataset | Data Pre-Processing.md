Imbalanced data set will have un-even class distributions

Example : Suppose you want to predict person has Diabates or not in the data set we have data for the persons who has around 1000 and who donâ€™t have around 100 in this case we cant feed the data and our modle will perform well

**Imbalanced Dataset:**
A dataset with an unequal class distribution

```
# importing the dependencies
import numpy as np
import pandas as pd
# loading the dataset to pandas DataFrame
credit_card_data = pd.read_csv('/content/credit_data.csv')
# first 5 rows of the dataframe
credit_card_data.head()
credit_card_data.tail()

# distribution of the two classes
credit_card_data['Class'].value_counts()
```
![image](https://github.com/user-attachments/assets/ce82f3b9-10fa-4682-86af-93f241ade210)
```
# separating the legit and fraudulent transactions
legit = credit_card_data[credit_card_data.Class == 0]
fraud = credit_card_data[credit_card_data.Class == 1]
print(legit.shape)
print(fraud.shape)
```

Under-sampling --> we are going build a new data set of 492 from legit samples and you will both legit of 492 and fraud data set of 492 to train the data sent 
Build a sample dataset containing similar distribution of Legit & Fraudulent Transactionds

Number of Fraudulent Transactions --> 492
```
legit_sample = legit.sample(n=492)
print(legit_sample.shape)
Concatenate the Two DataFrames
new_dataset = pd.concat([legit_sample, fraud], axis = 0) #here axis 0 means for column wise it will select random 492 data points
new_dataset.head()
new_dataset.tail()
new_dataset['Class'].value_counts()
```


**CodeFile**
```
**Imbalanced Dataset:**

A dataset with an unequal class distribution
# importing the dependencies
import numpy as np
import pandas as pd
# loading the dataset to pandas DataFrame
credit_card_data = pd.read_csv('/content/credit_data.csv')
# first 5 rows of the dataframe
credit_card_data.head()
credit_card_data.tail()
# distribution of the two classes
credit_card_data['Class'].value_counts()
This is Highly Imbalanced Dataset
0 --> Legit Transactions

1 --> Fraudulent Transactions
# separating the legit and fraudulent transactions
legit = credit_card_data[credit_card_data.Class == 0]
fraud = credit_card_data[credit_card_data.Class == 1]
print(legit.shape)
print(fraud.shape)
Under-sampling
Build a sample dataset containing similar distribution of Legit & Fraudulent Transactionds
Number of Fraudulent Transactions --> 492
legit_sample = legit.sample(n=492)
print(legit_sample.shape)
Concatenate the Two DataFrames
new_dataset = pd.concat([legit_sample, fraud], axis = 0)
new_dataset.head()
new_dataset.tail()
new_dataset['Class'].value_counts()

```
